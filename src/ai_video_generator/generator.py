import os
import requests
import asyncio
import edge_tts
from dashscope import ImageSynthesis  # é€šä¹‰åƒé—®ä½¿ç”¨å¦ä¸€å¥—
import json
from pathlib import Path
# from openai import OpenAI
'''å›¾åƒ & è¯­éŸ³ç”Ÿæˆå™¨æ¨¡å—'''

# æš‚æ—¶ä½¿ç”¨é€šä¹‰åƒæ–‡çš„
# client = OpenAI(api_key=input("è¯·è¾“å…¥å›¾ç‰‡æ¨¡å‹API"), base_url="https://dashscope.aliyuncs.com/compatible-mode/v1")
config = json.loads(Path("D:\download\config.json").read_text(encoding="utf-8"))
def generate_image(prompt: str, output_path: str):
    try:
        # è°ƒç”¨API
        response = ImageSynthesis.call(
            #api_key=input("è¾“å…¥å›¾ç‰‡ç”Ÿæˆå¤§æ¨¡å‹key:"),
            api_key=config["api_keys"]["dashscope"],
            model="wanx2.1-t2i-turbo",
            prompt=prompt,
            n=1,
            size='1080*1440'
        )

        print("APIå“åº”:", response)  # è°ƒè¯•ç”¨

        # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
        if response.status_code != 200 or response.output.task_status != "SUCCEEDED":
            error_msg = response.output.message if hasattr(response.output, 'message') else "æœªçŸ¥é”™è¯¯"
            raise Exception(f"å›¾ç‰‡ç”Ÿæˆå¤±è´¥: {error_msg} (ä»£ç : {getattr(response.output, 'code', 'æ— ')})")

        # ç¡®ä¿resultsä¸ä¸ºç©º
        if not response.output.results:
            raise Exception("æœªç”Ÿæˆä»»ä½•å›¾ç‰‡ç»“æœ")

        # è·å–å›¾ç‰‡URL
        url = response.output.results[0].url  # ä½¿ç”¨ç‚¹å·è®¿é—®å±æ€§

        # ä¸‹è½½å¹¶ä¿å­˜å›¾ç‰‡
        image_data = requests.get(url).content
        with open(output_path, "wb") as f:
            f.write(image_data)

        print(f"ğŸ–¼ï¸ å›¾ç‰‡å·²ç”Ÿæˆï¼š{output_path}")

    except Exception as e:
        print(f"âŒ é”™è¯¯: {str(e)}")
        # å¯ä»¥é€‰æ‹©è¿”å›Falseæˆ–é‡æ–°æŠ›å‡ºå¼‚å¸¸
        raise

async def generate_audio(text: str, output_path: str, voice="zh-CN-XiaoxiaoNeural"):
    communicate = edge_tts.Communicate(text, voice=voice)
    await communicate.save(output_path)
    print(f"ğŸ”Š è¯­éŸ³å·²ç”Ÿæˆï¼š{output_path}")


def generate_assets(sentence: str, tags: list[str], index: int, output_dir: str):
    """æ ¹æ®å¥å­å’Œtagç”Ÿæˆå›¾åƒå’ŒéŸ³é¢‘æ–‡ä»¶"""
    prompt = f"{sentence} " + " ".join([f"#{tag}" for tag in tags])
    img_path = os.path.join(output_dir, f"clip_{index:03}.jpg")
    audio_path = os.path.join(output_dir, f"clip_{index:03}.mp3")

    generate_image(prompt, img_path)
    asyncio.run(generate_audio(sentence, audio_path))

    return img_path, audio_path
